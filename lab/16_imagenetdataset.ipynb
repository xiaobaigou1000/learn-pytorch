{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5e1044",
   "metadata": {},
   "source": [
    "# AlexNet on Imagenet Dataset\n",
    "\n",
    "Code is running, but hyper parameters are bad, following method need to apply to improve results.\n",
    "\n",
    "1. Increase training epoches, 1000 classes need more training epoches to lower loss.\n",
    "2. Learning rate may be too high, lower to 0.003 or 0.001 may have better result.\n",
    "\n",
    "It's not wise to increase test count without enough understand of lightning framework. Plan to use small data sets to continue learning, and then come back to improve after familiar with lightning framework and tensorboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd0ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as L\n",
    "from torch.utils import data\n",
    "from torchvision.transforms import v2\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import Metric\n",
    "import torchmetrics\n",
    "from pytorch_lightning.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0212cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetDataset(L.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dataset_path = \"./data/imagenet/training_images/\"\n",
    "        self.test_dataset_path = \"./data/imagenet/validation_images/\"\n",
    "        self.image_transforms = v2.Compose(\n",
    "            [v2.ToImage(), v2.ToDtype(torch.float32, True), v2.Resize((224, 224))])\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 16\n",
    "\n",
    "    def prepare_data(self):\n",
    "        return super().prepare_data()\n",
    "\n",
    "    def setup(self, stage):\n",
    "        all_train_data = torchvision.datasets.ImageFolder(\n",
    "            self.train_dataset_path, self.image_transforms)\n",
    "        train_dataset, validation_dataset = data.random_split(\n",
    "            all_train_data, [0.8, 0.2])\n",
    "        self.train_dataset = train_dataset\n",
    "        self.validation_dataset = validation_dataset\n",
    "\n",
    "        test_dataset = torchvision.datasets.ImageFolder(\n",
    "            self.test_dataset_path, self.image_transforms)\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(self.train_dataset, self.batch_size, True, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return data.DataLoader(self.validation_dataset, self.batch_size, False, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return data.DataLoader(self.test_dataset, self.batch_size, False, num_workers=self.num_workers, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f03478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(L.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 1000)\n",
    "        )\n",
    "\n",
    "        self.learning_rate = 0.005\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(\n",
    "            task=\"multiclass\", num_classes=1000)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        output = self(X)\n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = self.accuracy(output, y)\n",
    "        self.log_dict({\"training_loss\": loss, \"train_accuracy\": accuracy},\n",
    "                      on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        output = self(X)\n",
    "        loss = self.loss(output, y)\n",
    "        accuracy = self.accuracy(output, y)\n",
    "        self.log_dict({\"validation_loss\": loss,\n",
    "                      \"validation_accuracy\": accuracy})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "            \"./data/imagenet/training_images/\", v2.Compose(\n",
    "                [v2.ToImage(), v2.ToDtype(torch.float32, True), v2.Resize((224, 224))])), 32, True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b8efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "f:\\code\\deep-learning\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "trainer = L.Trainer(accelerator='gpu', max_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5227215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | net      | Sequential         | 50.8 M | train\n",
      "1 | loss     | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------\n",
      "50.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.8 M    Total params\n",
      "203.376   Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2f6fc13d2e4a379daf97ed820be0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a6eb4f6a22489abd1532006e30a38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b75d68886224d7798cecbabca6b3b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cf59cdfe7f48ff805960499a34110c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b013038f774183adb1499d44bdcf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a5c03b90d74bc8a7e1b94a53f44d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb0cbec719a4152997604871cbfc09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9f247da39f4a5696ce05a5d03ee2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04acbc4b6ba74f998e6450adaae8a023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bff20d3a2e849f0b3cb7d9381b42ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd14d4f5395f47a3b5e2714dfb3b7792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caf8d5f29264c2c92066f96dcd7f2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "my_dataset = ImagenetDataset()\n",
    "trainer.fit(model, my_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
